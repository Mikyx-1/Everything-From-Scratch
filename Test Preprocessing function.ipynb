{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d546f66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tested successfully\n",
    "import onnxruntime as ort\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "# from utils.general import non_max_suppression\n",
    "import torch\n",
    "import time\n",
    "import torchvision\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e827a2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(image, modelWidth, modelHeight):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (modelWidth, modelHeight)).astype(np.float32)\n",
    "    image = np.transpose(image, (2, 0, 1))[None, ...]\n",
    "    image = image/255.\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba0db695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xywh2xyxy(x):\n",
    "    # Convert nx4 boxes from [x, y, w, h] to [x1, y1, x2, y2] where xy1=top-left, xy2=bottom-right\n",
    "    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)\n",
    "    y[:, 0] = x[:, 0] - x[:, 2] / 2  # top left x\n",
    "    y[:, 1] = x[:, 1] - x[:, 3] / 2  # top left y\n",
    "    y[:, 2] = x[:, 0] + x[:, 2] / 2  # bottom right x\n",
    "    y[:, 3] = x[:, 1] + x[:, 3] / 2  # bottom right y\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cccf58b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(prediction, conf_thres=0.25, iou_thres=0.45, classes=None, agnostic=False, multi_label=False,\n",
    "                        labels=(), max_det=300):\n",
    "    \"\"\"Runs Non-Maximum Suppression (NMS) on inference results\n",
    "\n",
    "    Returns:\n",
    "         list of detections, on (n,6) tensor per image [xyxy, conf, cls]\n",
    "    \"\"\"\n",
    "    nc = prediction.shape[2] - 5  # number of classes\n",
    "    xc = prediction[..., 4] > conf_thres  # candidates\n",
    "\n",
    "    # Checks\n",
    "    assert 0 <= conf_thres <= 1, f'Invalid Confidence threshold {conf_thres}, valid values are between 0.0 and 1.0'\n",
    "    assert 0 <= iou_thres <= 1, f'Invalid IoU {iou_thres}, valid values are between 0.0 and 1.0'\n",
    "\n",
    "    # Settings\n",
    "    min_wh, max_wh = 2, 7680  # (pixels) minimum and maximum box width and height\n",
    "    max_nms = 30000  # maximum number of boxes into torchvision.ops.nms()\n",
    "    time_limit = 10.0  # seconds to quit after\n",
    "    redundant = True  # require redundant detections\n",
    "    multi_label &= nc > 1  # multiple labels per box (adds 0.5ms/img)\n",
    "    merge = False  # use merge-NMS\n",
    "\n",
    "    t = time.time()\n",
    "    output = [torch.zeros((0, 6), device=prediction.device)] * prediction.shape[0]\n",
    "    for xi, x in enumerate(prediction):  # image index, image inference\n",
    "        # Apply constraints\n",
    "        x[((x[..., 2:4] < min_wh) | (x[..., 2:4] > max_wh)).any(1), 4] = 0  # width-height\n",
    "        x = x[xc[xi]]  # confidence\n",
    "\n",
    "        # Cat apriori labels if autolabelling\n",
    "        if labels and len(labels[xi]):\n",
    "            lb = labels[xi]\n",
    "            v = torch.zeros((len(lb), nc + 5), device=x.device)\n",
    "            v[:, :4] = lb[:, 1:5]  # box\n",
    "            v[:, 4] = 1.0  # conf\n",
    "            v[range(len(lb)), lb[:, 0].long() + 5] = 1.0  # cls\n",
    "            x = torch.cat((x, v), 0)\n",
    "\n",
    "        # If none remain process next image\n",
    "        if not x.shape[0]:\n",
    "            continue\n",
    "\n",
    "        # Compute conf\n",
    "        x[:, 5:] *= x[:, 4:5]  # conf = obj_conf * cls_conf\n",
    "\n",
    "        # Box (center x, center y, width, height) to (x1, y1, x2, y2)\n",
    "        box = xywh2xyxy(x[:, :4])\n",
    "\n",
    "        # Detections matrix nx6 (xyxy, conf, cls)\n",
    "        if multi_label:\n",
    "            i, j = (x[:, 5:] > conf_thres).nonzero(as_tuple=False).T\n",
    "            x = torch.cat((box[i], x[i, j + 5, None], j[:, None].float()), 1)\n",
    "        else:  # best class only\n",
    "            conf, j = x[:, 5:].max(1, keepdim=True)\n",
    "            x = torch.cat((box, conf, j.float()), 1)[conf.view(-1) > conf_thres]\n",
    "\n",
    "        # Filter by class\n",
    "        if classes is not None:\n",
    "            x = x[(x[:, 5:6] == torch.tensor(classes, device=x.device)).any(1)]\n",
    "\n",
    "        # Check shape\n",
    "        n = x.shape[0]  # number of boxes\n",
    "        if not n:  # no boxes\n",
    "            continue\n",
    "        elif n > max_nms:  # excess boxes\n",
    "            x = x[x[:, 4].argsort(descending=True)[:max_nms]]  # sort by confidence\n",
    "\n",
    "        # Batched NMS\n",
    "        c = x[:, 5:6] * (0 if agnostic else max_wh)  # classes\n",
    "        boxes, scores = x[:, :4] + c, x[:, 4]  # boxes (offset by class), scores\n",
    "        i = torchvision.ops.nms(boxes, scores, iou_thres)  # NMS\n",
    "        if i.shape[0] > max_det:  # limit detections\n",
    "            i = i[:max_det]\n",
    "        if merge and (1 < n < 3E3):  # Merge NMS (boxes merged using weighted mean)\n",
    "            # update boxes as boxes(i,4) = weights(i,n) * boxes(n,4)\n",
    "            iou = box_iou(boxes[i], boxes) > iou_thres  # iou matrix\n",
    "            weights = iou * scores[None]  # box weights\n",
    "            x[i, :4] = torch.mm(weights, x[:, :4]).float() / weights.sum(1, keepdim=True)  # merged boxes\n",
    "            if redundant:\n",
    "                i = i[iou.sum(1) > 1]  # require redundancy\n",
    "\n",
    "        output[xi] = x[i]\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f275087c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP Error D:\\a\\_work\\1\\s\\onnxruntime\\core\\session\\provider_bridge_ort.cc:1193 onnxruntime::ProviderLibrary::Get [ONNXRuntimeError] : 1 : FAIL : LoadLibrary failed with error 126 \"\" when trying to load \"C:\\Users\\Hoang Viet\\anaconda3\\envs\\virenv1\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_providers_tensorrt.dll\"\n",
      " when using ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n",
      "Falling back to ['CUDAExecutionProvider', 'CPUExecutionProvider'] and retrying.\n"
     ]
    }
   ],
   "source": [
    "sess = ort.InferenceSession(\"./phone_use_weights_jetson_nano/best.onnx\", providers = ort.get_available_providers())\n",
    "\n",
    "input_name = sess.get_inputs()[0].name\n",
    "\n",
    "image1 = cv2.imread(\"bus.jpg\")\n",
    "image2 = cv2.imread(\"zidane.jpg\")\n",
    "image3 = cv2.imread(\"image.jpg\")\n",
    "\n",
    "# preprocessed = preprocessing(image3, 640, 640)\n",
    "\n",
    "# prediction = sess.run(None, {\"images\": preprocessed})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a78b40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_torch = torch.from_numpy(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9e928b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[  5.5626, 266.4108, 278.2135, 602.6544,   0.8176,   0.0000]])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_max_suppression(prediction_torch, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2e6c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.rectangle(image3, (6, 266), (278, 603), (0, 255, 0), 2)\n",
    "plt.imshow(image3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "569e086d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hoang Viet\\anaconda3\\envs\\virenv1\\lib\\site-packages\\torch\\hub.py:286: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
      "  warnings.warn(\n",
      "Using cache found in C:\\Users\\Hoang Viet/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-7-28 Python-3.9.16 torch-2.0.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4090, 24564MiB)\n",
      "\n",
      "Loading phone_use_weights_jetson_nano\\best.onnx for ONNX Runtime inference...\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load(\"ultralytics/yolov5\", \"custom\", \"./phone_use_weights_jetson_nano/best.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83dcb64d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([], device='cuda:0', size=(0, 6))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(image3).xyxyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cbfe54b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2337b7391c0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(image3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f809bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virenv1",
   "language": "python",
   "name": "virenv1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
